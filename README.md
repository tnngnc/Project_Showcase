# üëã Hi, I'm Trung Nguyen

### Data Engineer | Analytics Engineer 

Welcome to my project portfolio! Here you will find a showcase of my **personal projects**, demonstrating my ability to build scalable data pipelines, interactive analytics dashboards, and robust engineering systems.

In my **current professional role**, I specialize in **Snowflake, DBT, Airflow, and Python**, focusing on creating value through clean code, modern architecture, and efficient data processing.

---

## üöÄ Featured Projects

### 1. [Stream_lit](https://github.com/tnngnc/Stream_it)
**Interactive Real-Time Data Dashboard**

A full-stack data visualization application built to monitor and analyze real-time data streams. This project demonstrates the ability to translate raw data into actionable insights through an intuitive user interface.

*   **Core Tech:** Python, Streamlit, Pandas, MySQL.
*   **Key Features:**
    *   **Live Data Monitoring:** Real-time metrics updates with low latency.
    *   **Interactive Charts:** Dynamic querying and filtering capabilities for end-users.
    *   **Responsive Design:** Optimized for both desktop and mobile viewing.
*   **Use Case:** Ideal for operations teams needing immediate visibility into system performance or financial metrics.

### 2. [Orchestration_Dagger](https://github.com/tnngnc/Orchestration_Dagger)
**Enterprise-Grade Data Pipeline Orchestration**

A comprehensive data orchestration system designed to manage complex dependency graphs and automate data flows. This project highlights my expertise in DataOps and backend engineering.

*   **Core Tech:** Python, Dagster (Dagger), Docker, SQL.
*   **Key Features:**
    *   **Asset-Based Definition:** Declarative management of data assets for clear lineage.
    *   **Resilient Scheduling:** Automated backfills, retry policies, and alert integrations.
    *   **Environment Isolation:** Fully dockerized execution for consistent deployment across dev/prod.
*   **Problem Solved:** Replaces brittle cron-based scheduling with a robust, observable graph of computations.


### 3. Tastytrade MCP Server
**Financial Data Access for AI Agents**

A server that implements the Model Context Protocol (MCP) to provide AI agents with access to Tastytrade's historical price data. This project enables seamless integration of financial market data into LLM-based workflows.

*   **Core Tech:** Python, Model Context Protocol (MCP), Tastytrade API, uv.
*   **Key Features:**
    *   **MCP Compliance:** Fully implements the MCP specification for tool exposure.
    *   **Market Data Tools:** Provides tools for retrieving historical candle data.
    *   **Secure & Robust:** Handles authentication securely and uses `uv` for dependency locking.
*   **Use Case:** Enables financial analysis agents to fetch and reason about stock market history.

---

## üõ†Ô∏è Technical Skills

*   **Languages:** Python, SQL
*   **Frameworks:** Airflow, DBT,Streamlit, Dagster
*   **Tools & Platforms:** Snowflake, Databricks, Docker, Git/GitHub, Linux, Cloud Services
*   **Concepts:** ETL/ELT pipelines, Data Warehousing, API Design, Agile Development

---

## üì´ Contact Me

I am always open to discussing data challenges and engineering opportunities.

*   [GitHub](https://github.com/tnngnc)
*   [Email](mailto:trunnc.ng@gmail.com)
*   [LinkedIn](https://www.linkedin.com/in/trungnguyen18/)
